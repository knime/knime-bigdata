<?xml version="1.0" encoding="UTF-8"?>
<knimeNode xmlns="http://knime.org/node/v3.1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://knime.org/node/v3.1 http://knime.org/node/v3.1.xsd"
  type="Predictor" icon="icon.png">
  <name>Spark Association Rule (Apply)</name>
  <shortDescription>Apply association rules in Apache Spark.</shortDescription>
  <fullDescription>
    <intro>
      <p>
        This node applies <a href="https://spark.apache.org/docs/2.2.0/mllib-frequent-pattern-mining.html#association-rules">association rules</a>
        created by a Spark rule learner*.
        The rules are applied to a given column with item sets (transactions). A rule matches an item set, if the item set contains all antecedent items
        of the rule. The consequent items of the matching rules are then added to the output set of predicted items
        if they are not already included in the input items collection (the output set contains only <i>new</i> items).
      </p>

      <p>
        To avoid memory and computations explosions, the number of used association rules can be limited.
        A warning will be added to the node if the limit is reached and only the first <i>n</i> rules are used (this means randomly chosen on a unsorted set of rules).
      </p>

      <p>
        The <i>Spark Association Rule Learner</i> Node can be used to generate the association rules.
        The <i>Spark GroupBy</i> or <i>Spark SQL</i> Node can be used to generate a collection of items as input.
      </p>

      <p>
        Rules with <i>missing values</i> in the selected antecedent or consequent column and
        item rows with <i>missing values</i> in the selected item column are <i>removed</i>.
      </p>

      <p><i>This node requires at least Apache Spark 2.0.</i></p>
      <br/>
      (*) RULE LEARNER is a registered trademark of Minitab, LLC and is used with Minitabâ€™s permission.
    </intro>

        <option name="Antecedent Column">
            Collection column from the first input table, which holds the antecedent item sets of the association rules.
        </option>
        <option name="Consequent Column">
            Column from the first input table, which holds the consequent items (one item per row) of the association rules.
        </option>
        <option name="Rule limit">
            Optional: Maximum number of association rules to use.
        </option>
        <option name="Item Column">
            Collection column from the second input table, which holds the transaction item sets to apply the association rules on.
        </option>
        <option name="Output Column">
            Name of the resulting output column, where each row holds a collection of the consequent items of the matching rules.
        </option>
    </fullDescription>

	<ports>
		<inPort index="0" name="Association rules">Spark DataFrame with association rules</inPort>
		<inPort index="1" name="Spark data">Spark DataFrame with item collection column</inPort>
		<outPort index="0" name="Spark data">
		  Spark DataFrame with output column that holds the items which were predicted according to the
		  association rules
		</outPort>
	</ports>
</knimeNode>
