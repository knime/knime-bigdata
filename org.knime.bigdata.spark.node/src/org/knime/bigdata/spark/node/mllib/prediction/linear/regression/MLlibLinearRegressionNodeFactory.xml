<?xml version="1.0" encoding="UTF-8"?>
<knimeNode xmlns="http://knime.org/node/v2.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
    xsi:schemaLocation="http://knime.org/node/v2.12 http://knime.org/node/v2.12.xsd" 
    type="Learner" icon="icon.png">
    <name>Spark Linear Regression Learner (MLlib)</name>
	<shortDescription>Linear regression model learning performed in Spark.</shortDescription>
	<fullDescription>
		<intro>
			This node applies the Apache Spark 
			<a href="http://spark.apache.org/docs/latest/mllib-linear-methods.html#linear-least-squares-lasso-and-ridge-regression">Linear Regression</a> algorithm.
			It outputs the learned model for later application.
			<p>
            Please note that all data must be numeric, including the label column. 
            Use the Spark Category To Number nodes to convert nominal values to
            numeric columns.
            </p>
            <p>
            Use the Spark Predictor node to apply the learned model to unseen data.
            </p>
		</intro>
    	       
        <option name="Regularizer">
            The purpose of the <a href="http://en.wikipedia.org/wiki/Regularization_(mathematics)">regularizer</a> is 
            to encourage simple models and avoid overfitting. For more details on supported regularizers see the 
            <a href="http://spark.apache.org/docs/latest/mllib-linear-methods.html#regularizers">Regularizers</a>
            section of the MLlib documentation.
        </option>
        <option name="Regularization">
            The fixed regularization parameter r &gt;= 0 defines the trade-off between the two goals 
            of minimizing the loss (i.e., training error) and minimizing model complexity (i.e., to avoid overfitting).
        </option>
        <option name="Number of iterations">
            The number of iterations the method should run.
        </option>
                
        <option name="Loss function">
            For more details on the supported loss functions see the
            <a href="http://spark.apache.org/docs/1.2.1/mllib-linear-methods.html#loss-functions">Loss function</a> 
            section of the MLlib documentation.
        </option>
        <option name="Step size">
            The initial step size of SGD for the first step. In subsequent steps, the step size 
            will decrease with stepSize/sqrt(t).
            Only available for SGD.
        </option>
        <option name="Fraction">
            The fraction of data to be used for each SGD iteration. 
            The default of 1.0 corresponds to deterministic/classical gradient descent.
            Only available for SGD.
        </option>

        <option name="Use feature scaling">
            Select this option to use feature scaling before model training to reduce the condition numbers which can 
            significantly help the optimizer converging faster.
            Whether to perform feature scaling before model training to reduce the condition numbers
            which can significantly help the optimizer converging faster. The scaling correction will be
            translated back to resulting model weights, so it's transparent to users.
        </option>
        <option name="Add intercept">Select this option to add intercept.</option>
        <option name="Validate data">Select this option if the algorithm should validate data before training.</option>
        
        <option name="Class column">The classification column. Must be numeric.</option>
        <option name="Feature Columns">The feature columns to learn the model from. Supports only numeric columns.</option>
    
	</fullDescription>

    <ports>
		<inPort index="0" name="Input data">Input Spark DataFrame/RDD</inPort>
        <outPort index="0" name="Linear Regression Model">Spark MLlib Linear Regression Model</outPort>
    </ports>
</knimeNode>
