<?xml version="1.0" encoding="UTF-8"?>
<knimeNode xmlns="http://knime.org/node/v3.1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://knime.org/node/v3.1 http://knime.org/node/v3.1.xsd"
	type="Other" icon="icon.png">
	<name>CSV to Spark</name>
	<shortDescription>Creates a Spark DataFrame/RDD from given CSV file.</shortDescription>
	<fullDescription>
		<intro>
			Creates a Spark DataFrame/RDD from given CSV file.
			
			See <a href="https://github.com/databricks/spark-csv">CSV Data Source documentation</a> for more information.
			
			<p><b>Notice:</b> This feature requires at least Apache Spark 1.5.</p>
		</intro>
		
        <option name="Driver">Upload data source driver or depend on cluster side provided driver.</option>
		<option name="Header">First line of files will be used to name columns and will not be included in data.</option>
		<option name="Delimiter">Character used as delimiter between columns (supports <a href="http://docs.oracle.com/javase/specs/jls/se8/html/jls-3.html#jls-3.10.6">escape sequences</a>, e.g. <i>\t</i> or <i>\u0123</i>).</option>
		<option name="Quote character">Quote character (delimiters inside quotes are ignored).</option>
		<option name="Escape character">Escape character (escaped quote characters are ignored).</option>
		<option name="Mode">
			Determines the parsing mode. By default it is PERMISSIVE.
			<ul>
				<li><b>PERMISSIVE:</b> tries to parse all lines: nulls are inserted for missing tokens and extra tokens are ignored.</li>
				<li><b>DROPMALFORMED:</b> drops lines which have fewer or more tokens than expected or tokens which do not match the schema.</li>
				<li><b>FAILFAST:</b> aborts with a RuntimeException if encounters any malformed line.</li>
			</ul>
		</option>
		<option name="Charset">Valid charset name (see <a href="https://docs.oracle.com/javase/8/docs/api/java/nio/charset/Charset.html">java.nio.charset.Charset</a>).</option>
		<option name="Schema">Automatically infers column types. It requires one extra pass over the data. All types will be assumed string otherwise.</option>
		<option name="Comments">Skip lines beginning with this character.</option>
		<option name="Null value">Specifies a string that indicates a null value, any fields matching this string will be set as nulls in the DataFrame.</option>
		<option name="Date format">
			Specifies a string that indicates the date format to use when reading dates or timestamps. Custom date formats follow the formats at <a href="https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html">java.text.SimpleDateFormat</a>. This applies to both DateType and TimestampType. By default, it is null which means trying to parse times and date by java.sql.Timestamp.valueOf() and java.sql.Date.valueOf().
		</option>
	</fullDescription>

	<ports>
		<inPort index="0" name="Remote file connection">Spark compatible connection (HDFS, WebHDFS, HttpFS, S3, Blob Storage, ...)</inPort>
		<inPort index="1" name="Spark context">Required Spark context.</inPort>
		<outPort index="0" name="Spark data">Spark DataFrame/RDD</outPort>
	</ports>
</knimeNode>
