<?xml version="1.0" encoding="UTF-8"?>
<knimeNode xmlns="http://knime.org/node/v2.12" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
    xsi:schemaLocation="http://knime.org/node/v2.12 http://knime.org/node/v2.12.xsd" 
    type="Learner" icon="icon.png">
    <name>Spark Linear Regression Learner</name>
	<shortDescription>Trains a linear regression model in Spark.</shortDescription>
	<fullDescription>
		<intro>
			Learns a linear regression model. Learning a linear regression model means minimizing a given loss function
			with regularization. This node uses the
			<a
				href="https://spark.apache.org/docs/3.0.1/ml-classification-regression.html#regression">
				spark.ml linear regression
			</a>
			implementation to train a regression model in Spark. The target column must be numeric, whereas the
			feature columns can be either nominal or numerical.
			<p>
				Use the
				<i>Spark Predictor (Regression)</i>
				node to apply the learned model to unseen data.
			</p>
			
			<p>Please refer to the  <a href="https://spark.apache.org/docs/3.0.1/api/scala/org/apache/spark/ml/regression/LinearRegression.html">
			Spark documentation</a> for a full description of the underlying algorithm.</p>
			
			<p><i>This node requires at least Apache Spark 2.4.</i></p>
		</intro>
		
		<tab name="Settings">
			<option name="Target column">
				A numeric column that contains the values to train with. Rows with missing values in this column will
				be ignored during model training.
			</option>

			<option name="Feature Columns">
				The feature columns to learn the model with. Both nominal and numeric columns are supported,
				whereby for nominal data dummy variables are automatically created as described in section
				<a
					href="https://en.wikipedia.org/wiki/Categorical_variable#Categorical_variables_in_regression">
					Categorical variables in regression
				</a>.
				The dialog allows to select the columns manually (by moving them to the right panel) or via a
				wildcard/regex selection (all columns whose names match the wildcard/regex are used for learning).
				In case of manual selection, the behavior for new columns (i.e. that are not available at the
				time you configure the node) can be specified as either Enforce exclusion (new columns are
				excluded and therefore not used for learning) or Enforce inclusion (new columns are included
				and therefore used for learning).
			</option>

			<option name="Loss function">
				The supported loss functions are <i>Squared Error</i> (default) and 
				<a href="https://en.wikipedia.org/wiki/Huber_loss">Huber.</a> Please refer to the  
				<a href="https://spark.apache.org/docs/3.0.1/api/scala/org/apache/spark/ml/regression/LinearRegression.html">
                    Spark documentation</a> for more information.
			</option>
			
			
			<option name="Standardize features">
				Whether to standardize the training features before fitting the model.
				Note that the coefficients of models will be always returned on the original scale.
			</option>

			<option name="Regularizer">
				The supported types of regularization are:
				<ul>
					<li>None (a.k.a. ordinary least squares)</li>
					<li>Ridge Regression (L2) using a given regularization parameter</li>
					<li>Lasso (L1) using a given regularization parameter</li>
					<li>Elastic Net (L1+L2) using a given regularization and Elastic Net parameter</li>
				</ul>
			</option>
		</tab>
		
		<tab name="Advanced">
			<option name="Solver">
				Supported solver algorithm used for optimization:
				<ul>
					<li>Auto (default) means that the solver algorithm is selected automatically.</li>
					<li>Limited-memory BFGS (L-BFGS), which is a limited-memory quasi-Newton optimization method.</li>
					<li>Normal Equation uses a normal equation solver.</li>
				</ul>
			</option>
			
            <option name="Maximum iterations">
                The maximum number of iterations, if not terminated by <i>Convergence tolerance</i>.
            </option>

			<option name="Convergence tolerance">
				Set the convergence tolerance of iterations. Smaller values lead to higher accuracy at the
				cost of more iterations. The number of iterations is always bounded by <i>Maximum iterations</i>.
			</option>
			
            <option name="Fit intercept">
                Whether to fit an intercept term or not.
            </option>
		</tab>
	</fullDescription>

    <ports>
		<inPort index="0" name="Input data">Input Spark DataFrame with training data.</inPort>
		<outPort index="0" name="Spark ML linear learner model (regression)">Spark ML linear learner model (regression)</outPort>
		<outPort index="1" name="Coefficients and Intercept">Coefficients and statistics of the linear regression model.</outPort>
		<outPort index="2" name="Model Statistics">Statistical measures of the learned regression model, when applied to the training
		dataset (RÂ², explained variance, ...)
		</outPort>
    </ports>
</knimeNode>
