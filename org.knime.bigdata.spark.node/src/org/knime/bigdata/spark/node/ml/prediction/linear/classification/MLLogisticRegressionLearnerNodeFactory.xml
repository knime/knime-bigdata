<?xml version="1.0" encoding="UTF-8"?>
<knimeNode xmlns="http://knime.org/node/v4.1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://knime.org/node/v4.1 http://knime.org/node/v4.1.xsd"
    type="Learner" icon="icon.png">
    <name>Spark Logistic Regression Learner</name>
	<shortDescription>Trains a logistic regression model in Spark.</shortDescription>
	<fullDescription>
		<intro>
			This node uses the
			<a
				href="https://spark.apache.org/docs/3.0.1/ml-classification-regression.html#logistic-regression">
				spark.ml logistic regression
			</a>
			implementation to train a logistic regression model in Spark, supporting different regularization options.
			The target column must be nominal, whereas the feature columns can be either nominal or numerical.
			<p>
				Use the
				<i>Spark Predictor (Classification)</i>
				node to apply the learned model to unseen data.
			</p>
			
			<p>Please refer to the  <a href="https://spark.apache.org/docs/3.0.1/api/scala/org/apache/spark/ml/classification/LogisticRegression.html">
			Spark documentation</a> for a full description of the underlying algorithm.</p>
			
			<p><i>This node requires at least Apache Spark 2.4.</i></p>
		</intro>
		
		<tab name="Settings">
			<option name="Target column">
				A nominal column that contains the values to train, also known as the <i>dependent variable</i>.
			</option>

			<option name="Feature Columns">
				The feature columns to learn the model with. Both nominal and numeric columns are supported,
				whereby for nominal data dummy variables are automatically created as described in section
				<a
					href="https://en.wikipedia.org/wiki/Categorical_variable#Categorical_variables_and_regression">
					Categorical variables and regression
				</a>.
				The dialog allows you to select the columns manually (by moving them to the right panel) or via a
				wildcard/regex selection (all columns whose names match the wildcard/regex are used for learning).
				In case of manual selection, the behavior for new columns (i.e. that are not available at the
				time you configure the node) can be specified as either Enforce exclusion (new columns are
				excluded and therefore not used for learning) or Enforce inclusion (new columns are included
				and therefore used for learning).
			</option>
			
			<option name="Standardize features">
				Whether to standardize the training features before fitting the model.
				Note that the coefficients of models will be always returned on the original scale.
			</option>

			<option name="Regularizer">
				The purpose of the <a href="http://en.wikipedia.org/wiki/Regularization_(mathematics)">regularizer</a> is to encourage
				simple models and avoid overfitting. The supported types of regularization are:
				<ul>
					<li>None (a.k.a. ordinary least squares)</li>
					<li>Ridge Regression (L2) using a given regularization parameter</li>
					<li>Lasso (L1) using a given regularization parameter</li>
					<li>Elastic Net (L1+L2) using a given regularization and Elastic Net parameter</li>
				</ul>
			</option>
			
		    <option name="Regularization parameter">
                Defines the regularization penalty.
		    </option>
		    
            <option name="Elastic net parameter">
                Defines the mixing parameter between L1 and L2 regularization. 0 corresponds to L2 regularization. 1 corresponds to L1 regularization.
                For values in (0,1), the penalty is a combination of L1 and L2.
            </option>

            <option name="Missing Values in Input Columns">
                Defines how rows with missing values in the target and feature columns should be handled:
                <ul>
                    <li>Ignore: Ignores the entire row during model training, if any of the input columns contain a missing value.</li>
                    <li>Fail: Aborts the node execution with an error, if any of the input columns contain a missing value.</li>
                </ul>
            </option>
		</tab>
		
		<tab name="Advanced">
            <option name="Maximum iterations">
                The maximum number of iterations, if not terminated by <i>Convergence tolerance</i>.
            </option>

			<option name="Convergence tolerance">
				Set the convergence tolerance of iterations. Smaller values lead to higher accuracy at the
				cost of more iterations. The number of iterations is always bounded by <i>Maximum iterations</i>.
			</option>
			
            <option name="Fit intercept">
                Whether to fit an intercept term or not.
            </option>
		</tab>
	</fullDescription>

    <ports>
		<inPort index="0" name="Input data">Input Spark DataFrame with training data.</inPort>
		<outPort index="0" name="Spark ML linear learner model (regression)">Spark ML linear learner model (regression)</outPort>
		<outPort index="1" name="Coefficients and Intercept">Coefficients and statistics of the logistic regression model.</outPort>
		<outPort index="2" name="Model Statistics">Statistical measures of the learned regression model, when applied to the training dataset</outPort>
    </ports>
</knimeNode>
