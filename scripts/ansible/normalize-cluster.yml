- name: Setup (inactive) user accounts on all nodes
  hosts: hadoop-hosts
  vars:
    cloudera_sshkey: 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCZEnealU8iCzaPf0CnyT0/2TWBCNvojsoeqR1Qyw9148BvZXIrSi6YODXpwJr27wZLCUQvnyiBzpixJKtgniq77YvjdCd0aJV3iscgkr+/bagliEhkwhdu0jjtvrD22cbyhIPZXj15AKYyKTZNtStJ4fp7C7n/ss9ytf+0a6W6dm8ISizsUNj8jaRTG6w3RYczKAIsfuggTFWf40jSUfyWtRmOTW0sEJw2pZnhaQj1BG/LrpDTi6hQB5W4TXaOF4hycngJPMiyfPOT5EwsnByrkeVRpOrHoc46Dy6rxL6NN/yLV1JWpnd+CresBVub5g7neHr1L9YJLNYHdLRKKPWh'
    bjoern_sshkey: 'ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAvj8G6PFJwFRKfqhKD8sqvGPEOwMMcECmq1xWAiz1U9obRSNbKNxn4nVkYqWhQTLogERSRcUc+itZdn1Ep7tuXJfk3I+yD0oRl2bY/cgKcfByl1Zu5pwzE8VosdYSosT0GayMnXcaTp3+oyx4Vt4CyZ8+htm+p7ZrKl1cRhXCOIWuDtbJkcPsNP+wCVpkJglj5UmYUW1Q95+/RC6XsXpv1mVyM0C47XbfWdG08+QwxKnhbZFZAWrRVkG3Q/z7R0MELrM1GMjhPjLTiDCASZc/MHsGRv7DzT6pHG8+JO3yBMnxkWtmaRXl3087Bo0ZQkK1IORNYcDAQsvlhHuwq9tw2Q== bjoern@eon'
    sascha_sshkey: 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDTok94F4WD1M++zGTN6VdLL6Vbww9tc53SAI6Wpw0Jle3gazkg6qB+AyORe6OQKoZwpartGBIs9hwhC1YWv1/6anovZEHc9bNwF7tkQyZelMZyng5RqZ6HSFTJaWKcAR1RD14jvIQESphkLorKp5KpU/ypo0uxj3NoQ3llMepY0qaMKBwTqaieBW9nGCF7CyQRuMJoFpNPtBpyzGYHjCCYR5aEFFhBzBialRZW+BM2zBbJp1DAwLmKDJVBuOGjO9YwR9/WN39n6JDJRcXU+6mzyDqQpq8EkllGJmiWjHiO7b7orGYzje+g+O2kLNOod1idJr/K6dNkR3jjqlJu/7qD sascha@belka'
    users_default_shell: '/bin/false'
    users_create_homedirs: 'false'
    users_default_password: 'x'
    # DO NOT remove this unless you know what you're doing! willshersystems.users will change
    # sudo configuration for admins in such a way that ec2-user may not be able to do sudo
    # without password!
    users_manage_admin_sudoers: false
  roles:
    - role: willshersystems.users
      users:
        - name: knime
          # password is 'knime'
          # password: '$6$al9wTvi/$LHNSfqOqM3FPs18IhSKDayGoTcgdXG5kSlrh.OvK1HdjEmIFuePC2oFbiVI3dM8FNOFACwwU.egkpDVv5rkZ..'
        - name: test
        - name: bjoern
        - name: tobias
        - name: sascha
  # tasks:
  #   - name: configure sudoers
  #     lineinfile:
  #       dest: /etc/sudoers.d/administrators
  #       regexp: '^%wheel '
  #       line: '%wheel ALL = (ALL) NOPASSWD: ALL'
  #       state: present
  #       create: yes
  #       validate: 'visudo -cf %s'

# things to do only on master nodes
- hosts: hadoop-hosts:&master-*
  tasks:
    - name: install epel-release package
      package: name=epel-release state=latest
    - name: install python-pip package
      package: name=python-pip state=latest
    - name: install virtual-env package
      package: name=python-virtualenv state=latest
    - name: install jq package
      package: name=jq state=latest
    - name: install awscli via pip
      pip: name=awscli state=latest
    # - name: copy knimeDNS init.d script
    #   copy: src=normalize_files/knimeDNS dest=/etc/init.d/knimeDNS owner=root group=root mode='u=rwx,go=rx'
    # - name: setup knimeDNS init.d script to start at boottime and execute it once
    #   service: name=knimeDNS enabled=yes state=restarted

# create user homedirs in secured clusters
- hosts: hadoop-hosts:&master-*:&secure-hosts
  tasks:
    - name: Copy hdfs keytab
      copy: src={{keytab_dir}}/{{hdfs_keytab}} dest=/root/hdfs.keytab owner=root mode=u=rw,go=

    - name: Get hdfs TGT
      shell: kdestroy ; kinit -kt /root/hdfs.keytab hdfs

    - name: create HDFS homedirs for users
      shell: for u in test tobias sascha knime bjoern ; do hdfs dfs -mkdir -p /user/$u ; hdfs dfs -chown -R $u /user/$u ; done

# create user homedirs in unsecured clusters
- hosts: hadoop-hosts:&master-*:!secure-hosts
  tasks:
    - name: create HDFS homedirs for users
      become: yes
      become_user: hdfs
      shell: for u in test tobias sascha knime bjoern ; do hdfs dfs -mkdir -p /user/$u ; hdfs dfs -chown -R $u /user/$u ; done


# - hosts: master-*
#   vars:
#     ansible_become_user: hdfs
#   tasks:
#     - name: upload cdr test data via SSH
#       copy: src=normalize_files/CDR dest=/tmp/ owner=hdfs
#     - name: upload iris test data via SSH
#       copy: src=normalize_files/iris dest=/tmp/ owner=hdfs
#     - shell: hdfs dfs -rm -r -f -skipTrash /demo/data
#     - shell: hdfs dfs -mkdir -p /demo/data
#     - shell: hdfs dfs -put -p /tmp/CDR /demo/data/
#     - shell: hdfs dfs -put -p /tmp/iris /demo/data/
#     - shell: hdfs dfs -chmod -R ugo+rx /demo
#     - shell: beeline -u "jdbc:hive2://localhost:10000/" -u hive -e "query..."

# - hosts: master-hdp-*
#   tasks:
#     - name: install httpfs via yum
#       yum: name=hadoop-httpfs state=latest
#
#     - name: Detect HDP version
#       shell: hdp-select status hadoop-httpfs | grep -o '[.0-9-]\+$'
#       register: hdpversion
#
#     - name: hdp-select httpfs
#       shell: hdp-select set hadoop-httpfs {{hdpversion.stdout}}
#
#     - name: copy httpfs.sh script
#       copy: src=normalize_files/httpfs.sh dest=/usr/hdp/{{hdpversion.stdout}}/hadoop-httpfs/sbin/httpfs.sh force=yes backup=yes
#
#     - name: link tomcat config
#       file: src=/etc/hadoop-httpfs/tomcat-deployment/conf dest=/usr/hdp/{{hdpversion.stdout}}/hadoop-httpfs/conf owner=root group=root state=link
#
#     - name: link hadoop-libexec
#       file: src=../hadoop/libexec dest=/usr/hdp/{{hdpversion.stdout}}/hadoop-httpfs/libexec owner=root group=root state=link
#
#     - name: copy httpfs-env.sh
#       copy: src=normalize_files/httpfs-env.sh dest=/etc/hadoop-httpfs/conf/httpfs-env.sh force=yes backup=yes
#
#     - stat: path=/usr/hdp/{{hdpversion.stdout}}/etc/rc.d/init.d/hadoop-httpfs
#       register: initd_old_location
#
#     - name: add httpfs init.d script
#       file: src=/usr/hdp/{{hdpversion.stdout}}/etc/rc.d/init.d/hadoop-httpfs dest=/etc/init.d/hadoop-httpfs owner=root group=root state=link
#       when: initd_old_location.stat.exists == True
#
#     - name: add httpfs init.d script
#       file: src=/usr/hdp/{{hdpversion.stdout}}/hadoop-httpfs/etc/rc.d/init.d/hadoop-httpfs dest=/etc/init.d/hadoop-httpfs owner=root group=root state=link
#       when: initd_old_location.stat.exists == False
#
#     - name: create logdir
#       file: path=/var/log/hadoop-httpfs state=directory owner=httpfs  group=httpfs
#     - service: name=hadoop-httpfs enabled=yes
#     - service: name=hadoop-httpfs state=started

    # ATTENTION: this breaks the HDP sandbox VMs!
    # - name: install jq via yum
    #   yum: name=jq state=latest
    # - name: Detect Ambari cluster name
    #   shell: curl -s -u admin:admin "http://localhost:8080/api/v1/clusters" | jq -r ".items[0].Clusters.cluster_name"
    #   register: ambcluster
    # - name: allow httpfs to impersonate others (set via ambari)
    #   shell: /var/lib/ambari-server/resources/scripts/configs.sh set localhost {{ambcluster.stdout}} core-site 'hadoop.proxyuser.httpfs.groups' '*' ; /var/lib/ambari-server/resources/scripts/configs.sh set localhost {{ambcluster.stdout}} core-site 'hadoop.proxyuser.httpfs.hosts' '*'
    # - name: allow httpfs to impersonate others (set directly into core-site.xml)
    #   blockinfile:
    #     dest: /etc/hadoop/conf/core-site.xml
    #     marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
    #     insertbefore: "</configuration>"
    #     content: |
    #       <property>
    #         <name>hadoop.proxyuser.httpfs.groups</name>
    #         <value>*</value>
    #       </property>
    #       <property>
    #         <name>hadoop.proxyuser.httpfs.hosts</name>
    #         <value>*</value>
    #       </property>
