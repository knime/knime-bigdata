# #####################################################
# Spark Jobserver
# #####################################################

The Spark Jobserver provides a RESTful interface for submitting and managing
Apache Spark jobs, jars, and job contexts. It was originally developed at Ooyala,
but the main development repository is now on GitHub:
 https://github.com/spark-jobserver/spark-jobserver

This is a binary build of the Spark Job Server, provided by KNIME.com AG
(http://www.knime.com/). It contains minor modifications to improve
compatibility of the Spark Job Server with major Hadoop distributions e.g
Hortonworks or Cloudera. The source code for this build can be found here:
 https://github.com/bjoernlohrmann/spark-jobserver

# #####################################################
# Installing & Configuration
# #####################################################
Please follow the Spark Job Server installation manual provided as PDF by KNIME.

# #####################################################
# Changelog
# #####################################################

2016-01-05 Fixed two issues:
- Added documentation aber Spark context creation timeout to environment.conf
 (is an otherwise undocumented setting)
- Deactivated JMX on TCP/9999 by default, as port is already taken in some cluster
 environments, leading to unspecific error message in sysout:
 Error: Exception thrown by the agent : java.lang.NullPointerException

2016-07-07 Updated Spark jobserver, boot-time startup improvements
- Updated to upstream release 0.6.2, which brings:
  - Support for Spark 1.5 and Spark 1.6
  - Multiple new features, such as experimental jvm-per-context (deactivated by
    default). See https://github.com/spark-jobserver/spark-jobserver/blob/master/notes
    for full summary.
- Bugfix in init.d script that sometimes prevented starting the jobserver

2016-07-21 User impersonation on Kerberos secured clusters
 - Added user impersonation support for Kerberos secured clusters. For
   a step-by-step guide on how to set this up please consult the "KNIME Spark Executor 
   Guide" (PDF) on the product website: https://www.knime.org/knime-spark-executor#install
 - The provided init.d script now runs Spark Jobserver as the Linux user "spark-jobserver"
   (previously: spark). 

2016-10-12 Close context with context-per-jvm fixed (spark-jobserver PR 624)

2016-11-03 LDAP User selection via the memberUid attribute (or any other attribute) added

2016-11-06 Default aggregated chunk size limit increased from 1M to 200M

2017-05-18
 - Create new context after context initialization errors fixed
 - Stop job manager (and remove context from jobserver list) if spark context was stopped
   (via context.stop() or killed YARN application)
