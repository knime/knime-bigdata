# #####################################################
# Spark Jobserver
# #####################################################

The Spark Jobserver provides a RESTful interface for submitting and managing
Apache Spark jobs, jars, and job contexts. It was originally developed at Ooyala,
but the main development repository is now on GitHub:
 https://github.com/spark-jobserver/spark-jobserver

This is a binary build of the Spark Job Server, provided by KNIME.com AG
(http://www.knime.com/). It contains minor modifications to improve
compatibility of the Spark Job Server with major Hadoop distributions e.g
Hortonworks or Cloudera. The source code for this build can be found here:
 https://github.com/bjoernlohrmann/spark-jobserver

# #####################################################
# Installing & Configuration
# #####################################################
Please follow the Spark Job Server installation manual provided as PDF by KNIME.

# #####################################################
# Changelog
# #####################################################

2016-01-05 Fixed two issues:
- Added documentation aber Spark context creation timeout to environment.conf
 (is an otherwise undocumented setting)
- Deactivated JMX on TCP/9999 by default, as port is already taken in some cluster
 environments, leading to unspecific error message in sysout:
 Error: Exception thrown by the agent : java.lang.NullPointerException

2016-07-07 Updated Spark jobserver, boot-time startup improvements
- Updated to upstream release 0.6.2, which brings:
  - Support for Spark 1.5 and Spark 1.6
  - Multiple new features, such as experimental jvm-per-context (deactivated by
    default). See https://github.com/spark-jobserver/spark-jobserver/blob/master/notes
    for full summary.
- Bugfix in init.d script that sometimes prevented starting the jobserver

2016-07-21 User impersonation on Kerberos secured clusters
 - Added user impersonation support for Kerberos secured clusters. For
   a step-by-step guide on how to set this up please consult the "KNIME Spark Executor
   Guide" (PDF) on the product website: https://www.knime.org/knime-spark-executor#install
 - The provided init.d script now runs Spark Jobserver as the Linux user "spark-jobserver"
   (previously: spark).

2016-10-12 Close context with context-per-jvm fixed (spark-jobserver PR 624)

2016-11-03 LDAP User selection via the memberUid attribute (or any other attribute) added

2016-11-06 Default aggregated chunk size limit increased from 1M to 200M

2017-07-12
 - New versions: 0.6.2.2-KNIME and 0.7.0.1-KNIME
 - Fixed bugs:
   - If jvm-per-context=true then Jobserver becomes unuseable after a context initialization
     has failed
   - If jvm-per-context=true then Jobserver becomes unuseable if Spark context was stopped
     externally (e.g. because killed YARN application)
   - If jvm-per-context=true then jobserver sometimes fails because of concurrent
     access to file-based H2 database
 - Enhancements:
   - Added startup script for Ubuntu 14
   - Changed default paths in /tmp so that only /tmp/spark-job-server will be
     created

 IMPORTANT NOTE: There have been significant changes to the defaults in environment.conf
 w.r.t. H2 database settings. When updating from 0.6.2.1-KNIME or earlier versions,
 you should start from scratch with a fresh default environment.conf and merge in the
 changes you have done.

 2017-09-11
  - New version: 0.7.0.2-KNIME
  - Enhancements: Added preview for YARN cluster deployment mode. The default
    is still YARN client deployment mode. YARN cluster deployment is undocumented
    and not yet recommended for production use. However, if you want to try it,
    please contact us at bigdata@knime.com
