== Overview

KNIME Server executes workflows, that may try to access Kerberos-secured services such as Apache Hive(TM), Apache Impala(TM) and Apache Hadoop(R) HDFS(TM).

This guide describes how to configure KNIME Server so that it can *authenticate* itself against Kerberos and then *impersonate* its own users towards Kerberos-secured cluster services.

=== What is user impersonation?

With user impersonation, it does not matter whether a user runs a workflow in KNIME Analytics Platform or on KNIME Server.
In both cases, all operations on the cluster will be performed *as that particular user* and the *same permissions and authorization rules* apply. This has the following advantages:

- Workflows that access a secured cluster run without modifications on KNIME Server.
- Authorization to access cluster resources (Hive tables, HDFS files, ...) is administered with the usual mechanisms, e.g. Apache Sentry(TM) or Apache Ranger(TM).

=== How does user impersonation work?

Let us assume that a user Jane runs a workflow on KNIME Server. The workflow is supposed to run a Hive query. 

image::impersonation_overview.png[]

The following sequence of events now takes place:

. She starts a workflow that connects to Hive. This workflow is now executed on KNIME Server, not Jane's machine.

. When the _Hive Connector_ node in the workflow is executed, KNIME Server first checks for a TGT (ticket granting ticket) in its own ticket cache. If there is no TGT, it reads the `krb5.conf` configuration file, connects to the KDC and authenticates itself. Instead of Jane's credentials, it uses the credentials configured on KNIME Server, i.e. a service principal such as `knimeserver/<host>@REALM` and a keytab file. The TGT will be stored in an in-memory ticket cache.

. To make a JDBC connection to Hive, the Hive JDBC driver on KNIME Server still requires an ST (service ticket), which it now requests from the KDC. The ST is only valid for connections between KNIME Server and the Hive instance.

. Now, the Hive JDBC driver opens a connection to Hive and authenticates itself with the ST as `knimeserver/<host>@REALM`.

. Since the workflow was started by Jane, the JDBC driver tells Hive, that all operations shall be performed **as user Jane**.

. Hive consults the Hadoop `core-site.xml` to verify that KNIME Server is indeed allowed to impersonate Jane. If not, it will return an error.

. Now, the workflow submits an SQL query via the JDBC connection. The query is executed on the cluster *as user Jane*.

. Hive checks whether user Jane has the necessary permissions to run the query. It employs its usual permission checking mechanism, e.g. Apache Sentry(TM) or Apache Ranger(TM). The query will succeed or fail, depending on whether *Jane* has the necessary permissions.
